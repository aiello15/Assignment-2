{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbjO60u7vz7X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def getTransform():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "    return transform\n"
      ],
      "metadata": {
        "id": "4XwC4Fga1sq2"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def loadImages(imageFolder, batchSize=32):\n",
        "\n",
        "\n",
        "    transform = getTransform()\n",
        "\n",
        "    dataset = ImageFolder(root=imageFolder, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=batchSize, shuffle=False)\n",
        "\n",
        "    sampleImg, _ = dataset[0]\n",
        "    print(\"Sample image shape after transform:\", sampleImg.shape)\n",
        "\n",
        "    return dataset, loader"
      ],
      "metadata": {
        "id": "60pPoK2b6QRk"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "import torch\n",
        "\n",
        "def getResnet18FeatureExtractor():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = resnet18(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Extract last convolutional layer (last conv of layer4)\n",
        "    returnNodes = {'layer4.1.conv2': 'features'}\n",
        "    featureExtractor = create_feature_extractor(model, return_nodes=returnNodes)\n",
        "\n",
        "    return featureExtractor, device\n"
      ],
      "metadata": {
        "id": "4x4h2FoMunDf"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Passes images in the loader through the feature extractor and\n",
        " #returns flattened features and labels.\n",
        "\n",
        "def extractFeatures(loader, featureExtractor, device):\n",
        "\n",
        "    allFeatures = []\n",
        "    allLabels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            features = featureExtractor(images)['features']\n",
        "            features = features.view(features.size(0), -1)  # flatten H x W x C\n",
        "            allFeatures.append(features.cpu())\n",
        "            allLabels.append(labels)\n",
        "\n",
        "    allFeatures = torch.cat(allFeatures)\n",
        "    allLabels = torch.cat(allLabels)\n",
        "\n",
        "    return allFeatures, allLabels\n"
      ],
      "metadata": {
        "id": "Vzfb5oYpwzC_"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def reduceTo2D(features):\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(features)\n",
        "\n",
        "    print(\"Original feature dim:\", features.shape[1])\n",
        "    print(\"Reduced feature dim:\", reduced.shape[1])\n",
        "\n",
        "    return reduced\n"
      ],
      "metadata": {
        "id": "0SqFfdWIXWWK"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, BisectingKMeans\n",
        "\n",
        "def kmeansApproach(features2D, K=3):\n",
        "    results = {}\n",
        "\n",
        "\n",
        "    kmRandom = KMeans(n_clusters=K, init='random', n_init=10)\n",
        "    results[\"KMeans_random\"] = kmRandom.fit_predict(features2D)\n",
        "\n",
        "\n",
        "    kmPlus = KMeans(n_clusters=K, init='k-means++', n_init=10)\n",
        "    results[\"KMeans_kmeans++\"] = kmPlus.fit_predict(features2D)\n",
        "\n",
        "\n",
        "    kmBisect = BisectingKMeans(n_clusters=K, init='random')\n",
        "    results[\"Bisecting_KMeans\"] = kmBisect.fit_predict(features2D)\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "2TRPgJ3cidCb"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import fowlkes_mallows_score, silhouette_score\n",
        "\n",
        "\n",
        "def evaluateClustering(predLabels, trueLabels=None, features=None, method=\"fowlkes\"):\n",
        "\n",
        "    method = method.lower()\n",
        "\n",
        "    if method == \"fowlkes\":\n",
        "        return fowlkes_mallows_score(trueLabels, predLabels)\n",
        "\n",
        "    elif method == \"silhouette\":\n",
        "        return silhouette_score(features, predLabels)\n",
        "\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "QJUs8WJlsvih"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "def spectralClusteringApproacha(X):\n",
        "    spectral = SpectralClustering(n_clusters=3, assign_labels='kmeans')\n",
        "    labels = spectral.fit_predict(X)\n",
        "    return labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h7jgieszs_P4"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "#First one was not producing desired clustering\n",
        "\n",
        "def spectralClusteringApproach(features2D):\n",
        "    # Use RBF kernel to compute similarity (default gamma=None uses 1/n_features)\n",
        "    affinity_matrix = rbf_kernel(features2D)\n",
        "\n",
        "    # Spectral Clustering with precomputed affinity to better separate clusters\n",
        "    spectral = SpectralClustering(n_clusters=3, affinity='precomputed', assign_labels='kmeans', random_state=42)\n",
        "    labels = spectral.fit_predict(affinity_matrix)\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "ZOHXyC46pcfK"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "def agglomerativeClusteringAll(features2D, n_clusters=3):\n",
        "\n",
        "    linkageMethods = ['single', 'complete', 'average', 'ward']\n",
        "    labelsDict = {}\n",
        "\n",
        "    for linkage in linkageMethods:\n",
        "        agglo = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
        "        labels = agglo.fit_predict(features2D)\n",
        "        labelsDict[linkage] = labels\n",
        "\n",
        "    return labelsDict\n"
      ],
      "metadata": {
        "id": "QBk3afAdDCPk"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dbscanApproach(pca2Dfeatures, neighborhoodRadius, minPointsInCluster):\n",
        "    from sklearn.cluster import DBSCAN\n",
        "\n",
        "    dbscanModel = DBSCAN(eps=neighborhoodRadius, min_samples=minPointsInCluster)\n",
        "    db = dbscanModel.fit(pca2Dfeatures)\n",
        "\n",
        "\n",
        "    labels = db.labels_\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "dfGYVLtmwv1Z"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testDbscanPair(features2D, eps, minSamples):\n",
        "    labels = dbscanApproach(features2D, eps, minSamples)\n",
        "\n",
        "    if labels is None or len(labels) == 0:\n",
        "        return 0, []\n",
        "\n",
        "\n",
        "    uniqueLabels = set(labels)\n",
        "    if -1 in uniqueLabels:\n",
        "        clusterCount = len(uniqueLabels) - 1\n",
        "    else:\n",
        "        clusterCount = len(uniqueLabels)\n",
        "\n",
        "    return clusterCount, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "HSPFckp6vizo"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def searchClusterSize(features2D, desired_clusters=3):\n",
        "    #Search for DBSCAN parameters that produce the desired number of clusters.\n",
        "\n",
        "    eps_values = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
        "    min_samples_values = [3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    for eps in eps_values:\n",
        "        for minSamples in min_samples_values:\n",
        "            clusterCount, labels = testDbscanPair(features2D, eps, minSamples)\n",
        "\n",
        "            if clusterCount == desired_clusters:\n",
        "                return eps, minSamples, labels\n",
        "\n",
        "    return None, None, None\n"
      ],
      "metadata": {
        "id": "CfhI7vfFwuEp"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateKMeansFamily():\n",
        "\n",
        "    results = kmeansApproach(features2D, K=3)\n",
        "\n",
        "\n",
        "    for name, labels in results.items():\n",
        "\n",
        "        fmScore = evaluateClustering(predLabels=labels, trueLabels=allLabels, method=\"fowlkes\")\n",
        "        scScore = evaluateClustering(predLabels=labels, features=features2D, method=\"silhouette\")\n",
        "\n",
        "\n",
        "        print(name, \"→ Fowlkes-Mallows:\", round(fmScore, 3), \"Silhouette:\", round(scScore, 3))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hNrYnie2v-G6"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateSpectralClustering(spectralLabels, allLabels, features2D):\n",
        "    fmScore = evaluateClustering(predLabels=spectralLabels, trueLabels=allLabels, method=\"fowlkes\")\n",
        "    scScore = evaluateClustering(predLabels=spectralLabels, features=features2D, method=\"silhouette\")\n",
        "\n",
        "    print(\"SpectralClustering → Fowlkes-Mallows:\", round(fmScore, 3), \"Silhouette:\", round(scScore, 3))\n"
      ],
      "metadata": {
        "id": "u7BLzHGEr-n9"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateAgglomerativeClustering():\n",
        "    # Compute labels for all linkage methods\n",
        "    aggloLabels = agglomerativeClusteringAll(features2D, n_clusters=3)  #(Integers)\n",
        "\n",
        "    # Evaluate each linkage method\n",
        "    for linkage, labels in aggloLabels.items():\n",
        "        fmScore = evaluateClustering(predLabels=labels, trueLabels=allLabels, method=\"fowlkes\")\n",
        "        scScore = evaluateClustering(predLabels=labels, features=features2D, method=\"silhouette\")\n",
        "\n",
        "        print(\"Agglomerative (\", linkage, \") → Fowlkes-Mallows:\", round(fmScore, 3), \"Silhouette:\", round(scScore, 3))\n"
      ],
      "metadata": {
        "id": "b8teK94_Mhok"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateDBSCAN(features2D, allLabels):\n",
        "\n",
        "    eps, minSamples, labels = searchClusterSize(features2D, desired_clusters=3)\n",
        "\n",
        "    if eps is None:\n",
        "        print(\"DBSCAN could not find 3 clusters.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    fmScore = evaluateClustering(predLabels=labels, trueLabels=allLabels, method=\"fowlkes\")\n",
        "    scScore = evaluateClustering(predLabels=labels, features=features2D, method=\"silhouette\")\n",
        "\n",
        "    return eps, minSamples, fmScore, scScore, labels\n"
      ],
      "metadata": {
        "id": "1JPbGDcvdZpa"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1 Load dataset\n",
        "imageFolder = \"/content/drive/MyDrive/DataSets/Covid/Covid19-dataset/allImages\"\n",
        "dataset, loader = loadImages(imageFolder)\n",
        "\n",
        "# 2 Transforms\n",
        "transform = getTransform()\n",
        "\n",
        "# 3 Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 4 Feature extractor\n",
        "featureExtractor, device = getResnet18FeatureExtractor()\n",
        "\n",
        "# 5 Extract features\n",
        "allFeatures, allLabels = extractFeatures(loader, featureExtractor, device)\n",
        "\n",
        "# 6 PCA to 2D\n",
        "features2D = reduceTo2D(allFeatures.numpy())\n",
        "\n",
        "#7. Call Kmean Family\n",
        "kmeanFamily=kmeansApproach(features2D)\n",
        "print(kmeanFamily)\n",
        "\n",
        "\n",
        "#9. Spectral Clustering\n",
        "spectralLabels = spectralClusteringApproach(features2D)\n",
        "print(\"Spectral clustering labels:\", spectralLabels)\n",
        "\n",
        "#10 Find parameter to get 3 clusters:\n",
        "eps,minSamples,labels=searchClusterSize(features2D, 3)\n",
        "print(\"Eps and min samples\\t\",eps,\"\\t\",minSamples)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mo3JLHUoXo_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8bb654-f0a2-40f5-b3cc-4b7c94f2a557"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample image shape after transform: torch.Size([3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original feature dim: 25088\n",
            "Reduced feature dim: 2\n",
            "{'KMeans_random': array([2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
            "       0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2,\n",
            "       0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
            "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
            "       1, 1, 0, 1, 0, 1, 1, 0, 1], dtype=int32), 'KMeans_kmeans++': array([1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
            "       2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
            "       2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2,\n",
            "       0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2,\n",
            "       0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
            "       0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0,\n",
            "       0, 0, 2, 0, 2, 0, 0, 2, 0], dtype=int32), 'Bisecting_KMeans': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2,\n",
            "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1,\n",
            "       1, 0, 0, 1, 2, 1, 1, 0, 1], dtype=int32)}\n",
            "Spectral clustering labels: [0 1 0 0 0 0 2 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
            " 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 2 2 1 1 2 2 2 1\n",
            " 1 1 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1\n",
            " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2]\n",
            "Eps and min samples\t 0.2 \t 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateKMeansFamily()\n",
        "evaluateAgglomerativeClustering()\n",
        "spectralLabels = spectralClusteringApproach(features2D)\n",
        "evaluateSpectralClustering(spectralLabels, allLabels, features2D)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqZwlqiVKZUM",
        "outputId": "34d89426-ea8b-4abc-f0ff-329ebf935fb4"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans_random → Fowlkes-Mallows: 0.679 Silhouette: 0.548\n",
            "KMeans_kmeans++ → Fowlkes-Mallows: 0.679 Silhouette: 0.548\n",
            "Bisecting_KMeans → Fowlkes-Mallows: 0.763 Silhouette: 0.512\n",
            "Agglomerative ( single ) → Fowlkes-Mallows: 0.578 Silhouette: -0.273\n",
            "Agglomerative ( complete ) → Fowlkes-Mallows: 0.577 Silhouette: 0.492\n",
            "Agglomerative ( average ) → Fowlkes-Mallows: 0.634 Silhouette: 0.533\n",
            "Agglomerative ( ward ) → Fowlkes-Mallows: 0.621 Silhouette: 0.516\n",
            "SpectralClustering → Fowlkes-Mallows: 0.688 Silhouette: 0.544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps, minSamples, fm, sc, db_labels = evaluateDBSCAN(features2D, allLabels)\n",
        "\n",
        "if eps is not None:\n",
        "    print(\"=== DBSCAN Evaluation ===\")\n",
        "    print(\"eps:\", eps)\n",
        "    print(\"min_samples:\", minSamples)\n",
        "    print(\"Fowlkes-Mallows:\", round(fm, 3))\n",
        "    print(\"Silhouette Score:\", round(sc, 3))\n",
        "else:\n",
        "    print(\"DBSCAN could not produce 3 clusters with provided grid.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUjOfiA5eJZ-",
        "outputId": "9542af49-1b30-4b09-df87-577243951309"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DBSCAN Evaluation ===\n",
            "eps: 0.2\n",
            "min_samples: 4\n",
            "Fowlkes-Mallows: 0.554\n",
            "Silhouette Score: -0.086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Not necessary, but illustrates the search\n",
        "eps_values = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "min_samples_values = [2,3,4,5,6]\n",
        "\n",
        "\n",
        "for eps in eps_values:\n",
        "    for minSamples in min_samples_values:\n",
        "        clusterCount, labels = testDbscanPair(features2D, eps, minSamples)\n",
        "        print(f\"eps={eps}, minSamples={minSamples} → clusters={clusterCount}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oYpuCbXyg8v",
        "outputId": "235afa2d-a434-4ade-e332-cf800deaf9f5"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eps=0.1, minSamples=2 → clusters=19\n",
            "eps=0.1, minSamples=3 → clusters=0\n",
            "eps=0.1, minSamples=4 → clusters=0\n",
            "eps=0.1, minSamples=5 → clusters=0\n",
            "eps=0.1, minSamples=6 → clusters=0\n",
            "eps=0.15, minSamples=2 → clusters=27\n",
            "eps=0.15, minSamples=3 → clusters=1\n",
            "eps=0.15, minSamples=4 → clusters=1\n",
            "eps=0.15, minSamples=5 → clusters=1\n",
            "eps=0.15, minSamples=6 → clusters=0\n",
            "eps=0.2, minSamples=2 → clusters=44\n",
            "eps=0.2, minSamples=3 → clusters=7\n",
            "eps=0.2, minSamples=4 → clusters=3\n",
            "eps=0.2, minSamples=5 → clusters=1\n",
            "eps=0.2, minSamples=6 → clusters=0\n",
            "eps=0.25, minSamples=2 → clusters=50\n",
            "eps=0.25, minSamples=3 → clusters=10\n",
            "eps=0.25, minSamples=4 → clusters=4\n",
            "eps=0.25, minSamples=5 → clusters=1\n",
            "eps=0.25, minSamples=6 → clusters=0\n",
            "eps=0.3, minSamples=2 → clusters=57\n",
            "eps=0.3, minSamples=3 → clusters=13\n",
            "eps=0.3, minSamples=4 → clusters=7\n",
            "eps=0.3, minSamples=5 → clusters=2\n",
            "eps=0.3, minSamples=6 → clusters=0\n",
            "eps=0.35, minSamples=2 → clusters=58\n",
            "eps=0.35, minSamples=3 → clusters=24\n",
            "eps=0.35, minSamples=4 → clusters=7\n",
            "eps=0.35, minSamples=5 → clusters=4\n",
            "eps=0.35, minSamples=6 → clusters=1\n",
            "eps=0.4, minSamples=2 → clusters=60\n",
            "eps=0.4, minSamples=3 → clusters=32\n",
            "eps=0.4, minSamples=4 → clusters=12\n",
            "eps=0.4, minSamples=5 → clusters=4\n",
            "eps=0.4, minSamples=6 → clusters=3\n",
            "eps=0.45, minSamples=2 → clusters=53\n",
            "eps=0.45, minSamples=3 → clusters=26\n",
            "eps=0.45, minSamples=4 → clusters=19\n",
            "eps=0.45, minSamples=5 → clusters=9\n",
            "eps=0.45, minSamples=6 → clusters=3\n",
            "eps=0.5, minSamples=2 → clusters=50\n",
            "eps=0.5, minSamples=3 → clusters=24\n",
            "eps=0.5, minSamples=4 → clusters=19\n",
            "eps=0.5, minSamples=5 → clusters=10\n",
            "eps=0.5, minSamples=6 → clusters=8\n",
            "eps=0.6, minSamples=2 → clusters=40\n",
            "eps=0.6, minSamples=3 → clusters=23\n",
            "eps=0.6, minSamples=4 → clusters=17\n",
            "eps=0.6, minSamples=5 → clusters=15\n",
            "eps=0.6, minSamples=6 → clusters=10\n",
            "eps=0.7, minSamples=2 → clusters=28\n",
            "eps=0.7, minSamples=3 → clusters=20\n",
            "eps=0.7, minSamples=4 → clusters=11\n",
            "eps=0.7, minSamples=5 → clusters=10\n",
            "eps=0.7, minSamples=6 → clusters=13\n",
            "eps=0.8, minSamples=2 → clusters=19\n",
            "eps=0.8, minSamples=3 → clusters=16\n",
            "eps=0.8, minSamples=4 → clusters=11\n",
            "eps=0.8, minSamples=5 → clusters=10\n",
            "eps=0.8, minSamples=6 → clusters=8\n",
            "eps=0.9, minSamples=2 → clusters=12\n",
            "eps=0.9, minSamples=3 → clusters=10\n",
            "eps=0.9, minSamples=4 → clusters=9\n",
            "eps=0.9, minSamples=5 → clusters=10\n",
            "eps=0.9, minSamples=6 → clusters=5\n"
          ]
        }
      ]
    }
  ]
}